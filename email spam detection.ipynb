{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd007aa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Unidecode in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: autocorrect in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from wordcloud) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from wordcloud) (3.5.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from wordcloud) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Requirement already satisfied: spacy in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (1.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (6.3.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (61.2.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (1.0.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.6.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\murali vj\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: unknown command \"upgrade\"\n",
      "\n",
      "ERROR: unknown command \"upgrade\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install Unidecode\n",
    "!pip install autocorrect\n",
    "!pip install wordcloud\n",
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594d7955",
   "metadata": {},
   "source": [
    "# Importing Important libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a268793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Murali\n",
      "[nltk_data]     Vj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to C:\\Users\\Murali\n",
      "[nltk_data]     Vj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Murali\n",
      "[nltk_data]     Vj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Murali\n",
      "[nltk_data]     Vj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# to read and manipuate data\n",
    "import pandas as pd\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "# to visualize data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Helps to dispay the images\n",
    "import PIL as Image\n",
    "\n",
    "# To extract data using regular expression\n",
    "import re\n",
    "\n",
    "# Helps to remove the punctuation\n",
    "import string\n",
    "\n",
    "#Helps to remove the accented characters\n",
    "import unidecode\n",
    "\n",
    "# It helps to correct the spellings\n",
    "from autocorrect import Speller\n",
    "\n",
    "# Importing the nltk library\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')    # Loading the stopwords\n",
    "nltk.download('punkt')        # Loading the punkt module, used in Tokenization\n",
    "nltk.download('omw-1.4')      # Dependency for Tokenization\n",
    "nltk.download('wordnet')      # Loading the wordnet module, used in stemming and lemmatization\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Using in stemming\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "# Used in lemmatization\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "\n",
    "from spacy.lang.en import English\n",
    "en_nlp = English()\n",
    "\n",
    "# Used in Tokenization\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "# Importing the spacy library\n",
    "\n",
    "# Helped to create train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importing the Random Forest model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Metrics to evaluate the model\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c927746",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "Important - Please note that the code for importing the dataset will vary depending on the IDE used for coding. This code is for google colab - loading csv which is stored in google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e8ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading dataset\n",
    "messages = pd.read_csv('spam_detector.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b753d26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of dataset\n",
    "data = messages.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b68468a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hope you are having a good week. Just checking in ñó ñó</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>K..going bacckk to stävänger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Am also dong in cbe ony. Bt have to pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Are you this much buzy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Please ask mummy to call father</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type                                                     text\n",
       "0  ham  Hope you are having a good week. Just checking in ñó ñó\n",
       "1  ham                             K..going bacckk to stävänger\n",
       "2  ham                  Am also dong in cbe ony. Bt have to pay\n",
       "3  ham                                   Are you this much buzy\n",
       "4  ham                          Please ask mummy to call father"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b35727b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5055</th>\n",
       "      <td>spam</td>\n",
       "      <td>Sunshine Quiz Wkly Q! Win a top Sony DVD player if u know which country Liverpool played in mid week? Txt ansr to 82277. £1.50 SP:Tyrone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5056</th>\n",
       "      <td>spam</td>\n",
       "      <td>\"HOT LIVE FANTASIES call now 08707509020 Just 20p per min NTT Ltd PO Box 1327 Croydon CR9 5WB 0870 is a national rate call\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>spam</td>\n",
       "      <td>Ur balance is now £500. Ur next question is: Who sang 'Uptown Girl' in the 80's ? 2 answer txt ur ANSWER to 83600. Good luck!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5058</th>\n",
       "      <td>spam</td>\n",
       "      <td>\"If you don't your prize will go to another customer. T&amp;C at www.t-c.biz 18+ 150p/min Polo Ltd Suite 373 London W1J 6HL Please call back if busy \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5059</th>\n",
       "      <td>spam</td>\n",
       "      <td>\"SMS. ac JSco: Energy is high but u may not know where 2channel it. 2day ur leadership skills r strong. Psychic? Reply ANS w/question. End? Reply END JSCO\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  \\\n",
       "5055  spam   \n",
       "5056  spam   \n",
       "5057  spam   \n",
       "5058  spam   \n",
       "5059  spam   \n",
       "\n",
       "                                                                                                                                                             text  \n",
       "5055                     Sunshine Quiz Wkly Q! Win a top Sony DVD player if u know which country Liverpool played in mid week? Txt ansr to 82277. £1.50 SP:Tyrone  \n",
       "5056                                  \"HOT LIVE FANTASIES call now 08707509020 Just 20p per min NTT Ltd PO Box 1327 Croydon CR9 5WB 0870 is a national rate call\"  \n",
       "5057                                Ur balance is now £500. Ur next question is: Who sang 'Uptown Girl' in the 80's ? 2 answer txt ur ANSWER to 83600. Good luck!  \n",
       "5058           \"If you don't your prize will go to another customer. T&C at www.t-c.biz 18+ 150p/min Polo Ltd Suite 373 London W1J 6HL Please call back if busy \"  \n",
       "5059  \"SMS. ac JSco: Energy is high but u may not know where 2channel it. 2day ur leadership skills r strong. Psychic? Reply ANS w/question. End? Reply END JSCO\"  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97e4ce43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5060, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc76878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5060 entries, 0 to 5059\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   type    5060 non-null   object\n",
      " 1   text    5060 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 79.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a250074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking duplicate values\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0afe70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing duplicate values\n",
    "data = data.drop_duplicates(keep = 'first')\n",
    "\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff894486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index of the dataframe\n",
    "data = data.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82306364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ham     0.861486\n",
      "spam    0.138514\n",
      "Name: type, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#lets look at the distribution o ham and spam\n",
    "sns.countplot(x = 'type',data=data)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Checking percentage of ham and spam\n",
    "print(data['type'].value_counts(normalize=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e395e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'URGENT! We are trying to contact U. Todays draw shows that you have won a £800 prize GUARANTEED. Call 09050001808 from land line. Claim M95. Valid12hrs only'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][4320]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cecc690",
   "metadata": {},
   "source": [
    "## Text Preprocessing Step 1\n",
    "### Removing accented characters from the text\n",
    "Accents are special string characters generally adapted from other languages. They are not considered a major part of English.\n",
    "By using the unidecode library, we can transliterate any unicode string into the closest possible representation in ASCII text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd4122d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Hope you are having a good week. Just checking in ñó ñó\n",
       "1                               K..going bacckk to stävänger\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at the first 2 texts\n",
    "data['text'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35573801",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    t = data['text'][i].split()\n",
    "    # applying the unidecode data on a sentence and replace the accented word\n",
    "    new_text = [unidecode.unidecode(word) for word in t]  \n",
    "    \n",
    "    # Combining the seperated values\n",
    "    new_text = ' '.join(new_text)\n",
    "    # append new text to the list\n",
    "    text.append(new_text)\n",
    "\n",
    "data['cleaned data']=text\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02267e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hope you are having a good week. Just checking in ñó ñó</td>\n",
       "      <td>Hope you are having a good week. Just checking in no no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K..going bacckk to stävänger</td>\n",
       "      <td>K..going bacckk to stavanger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Am also dong in cbe ony. Bt have to pay</td>\n",
       "      <td>Am also dong in cbe ony. Bt have to pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are you this much buzy</td>\n",
       "      <td>Are you this much buzy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "0  Hope you are having a good week. Just checking in ñó ñó   \n",
       "1                             K..going bacckk to stävänger   \n",
       "2                  Am also dong in cbe ony. Bt have to pay   \n",
       "3                                   Are you this much buzy   \n",
       "\n",
       "                                              cleaned data  \n",
       "0  Hope you are having a good week. Just checking in no no  \n",
       "1                             K..going bacckk to stavanger  \n",
       "2                  Am also dong in cbe ony. Bt have to pay  \n",
       "3                                   Are you this much buzy  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0:3,['text','cleaned data']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be986f5",
   "metadata": {},
   "source": [
    "## Text Preprocessing Step 2\n",
    "#### Removing special characters from the text\n",
    "The function isalnum() method returns True if all the characters are alphanumeric, meaning alphabet letter (a-z) and numbers (0-9). By using this function we can retrive the data which consists of only letters and numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fac289b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yup bathe liao...'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29d85d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yup', 'bathe', 'liao...']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = data['text'][75].split()\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aceb96d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New list with only alphabets and numbers:  ['Yup', 'bathe']\n",
      "Original text:  Yup bathe\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "\n",
    "for i in example:\n",
    "    if i.isalnum():\n",
    "        new_text = i\n",
    "        text.append(new_text)\n",
    "\n",
    "print('New list with only alphabets and numbers: ', text)\n",
    "\n",
    "print('Original text: ',' '.join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e1b70bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    word = data['cleaned data'][i].split()\n",
    "    new_text = ' '.join([element for element in word if element.isalnum()])\n",
    "    text.append(new_text)\n",
    "\n",
    "data['cleaned text'] = text\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e88d82a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K..going bacckk to stävänger</td>\n",
       "      <td>bacckk to stavanger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K I'll be sure to get up before noon and see what's what</td>\n",
       "      <td>K be sure to get up before noon and see what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Yup bathe liao...</td>\n",
       "      <td>Yup bathe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>I am getting threats from your sales executive Shifad as i raised complaint against him. Its an official message.</td>\n",
       "      <td>I am getting threats from your sales executive Shifad as i raised complaint against Its an official</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>No i'm not gonna be able to. || too late notice. || i'll be home in a few weeks anyway. || what are the plans</td>\n",
       "      <td>No not gonna be able too late be home in a few weeks what are the plans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Dont show yourself. How far. Put new pictures up on facebook.</td>\n",
       "      <td>Dont show How Put new pictures up on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                  text  \\\n",
       "1                                                                                         K..going bacckk to stävänger   \n",
       "10                                                            K I'll be sure to get up before noon and see what's what   \n",
       "75                                                                                                   Yup bathe liao...   \n",
       "76   I am getting threats from your sales executive Shifad as i raised complaint against him. Its an official message.   \n",
       "98       No i'm not gonna be able to. || too late notice. || i'll be home in a few weeks anyway. || what are the plans   \n",
       "101                                                      Dont show yourself. How far. Put new pictures up on facebook.   \n",
       "\n",
       "                                                                                            cleaned text  \n",
       "1                                                                                    bacckk to stavanger  \n",
       "10                                                          K be sure to get up before noon and see what  \n",
       "75                                                                                             Yup bathe  \n",
       "76   I am getting threats from your sales executive Shifad as i raised complaint against Its an official  \n",
       "98                               No not gonna be able too late be home in a few weeks what are the plans  \n",
       "101                                                                 Dont show How Put new pictures up on  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[[1,10,75,76,98,101],['text','cleaned text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b765e10",
   "metadata": {},
   "source": [
    "#### There is an other way of deaing with special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "151b9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = []\n",
    "\n",
    "pattern = '[^A-Za-z0-9]+'\n",
    "\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    words = data['cleaned data'][i].split()\n",
    "    new_text = ''.join(re.sub(pattern, ' ',data['cleaned data'][i]))\n",
    "    text.append(new_text)\n",
    "data['cleaned data'] = text\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91db9293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hope you are having a good week. Just checking in ñó ñó</td>\n",
       "      <td>Hope you are having a good week Just checking in no no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K..going bacckk to stävänger</td>\n",
       "      <td>K going bacckk to stavanger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Am also dong in cbe ony. Bt have to pay</td>\n",
       "      <td>Am also dong in cbe ony Bt have to pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are you this much buzy</td>\n",
       "      <td>Are you this much buzy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "0  Hope you are having a good week. Just checking in ñó ñó   \n",
       "1                             K..going bacckk to stävänger   \n",
       "2                  Am also dong in cbe ony. Bt have to pay   \n",
       "3                                   Are you this much buzy   \n",
       "\n",
       "                                             cleaned data  \n",
       "0  Hope you are having a good week Just checking in no no  \n",
       "1                             K going bacckk to stavanger  \n",
       "2                  Am also dong in cbe ony Bt have to pay  \n",
       "3                                  Are you this much buzy  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0:3,['text','cleaned data']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf47e6c4",
   "metadata": {},
   "source": [
    "## Text Preprocessing Step 3\n",
    "### Lowercasing\n",
    "Lowercasing is an important text preprocessing technique. The goal is to change the input text's case so that the words \"text,\" \"Text,\" and \"TEXT\" are all treated equally. Strings in Python are of course case-sensitive, so Python will not automatically do this for us.\n",
    "Lowercasing helps reduce duplication and obtain accurate counts - it is hence an important part of various \"feature extraction\" approaches for text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d12c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining an empty list\n",
    "text = []\n",
    "\n",
    "# looping over each message in the data\n",
    "for i in range(data.shape[0]):\n",
    "    # lowecasing the text using the lower() function\n",
    "    new_text = data['cleaned data'][i].lower()\n",
    "    text.append(new_text)\n",
    "\n",
    "data['cleaned data'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "135a03cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4320</th>\n",
       "      <td>URGENT! We are trying to contact U. Todays draw shows that you have won a £800 prize GUARANTEED. Call 09050001808 from land line. Claim M95. Valid12hrs only</td>\n",
       "      <td>we are trying to contact todays draw shows that you have won a ps800 prize call 09050001808 from land claim valid12hrs only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>Bloomberg -Message center +447797706009 Why wait? Apply for your future http://careers. bloomberg.com</td>\n",
       "      <td>bloomberg center why apply for your future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4322</th>\n",
       "      <td>WIN a £200 Shopping spree every WEEK Starting NOW. 2 play text STORE to 88039. SkilGme. TsCs08714740323 1Winawk! age16 £1.50perweeksub.</td>\n",
       "      <td>win a ps200 shopping spree every week starting 2 play text store to tscs08714740323 age16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                              text  \\\n",
       "4320  URGENT! We are trying to contact U. Todays draw shows that you have won a £800 prize GUARANTEED. Call 09050001808 from land line. Claim M95. Valid12hrs only   \n",
       "4321                                                         Bloomberg -Message center +447797706009 Why wait? Apply for your future http://careers. bloomberg.com   \n",
       "4322                       WIN a £200 Shopping spree every WEEK Starting NOW. 2 play text STORE to 88039. SkilGme. TsCs08714740323 1Winawk! age16 £1.50perweeksub.   \n",
       "\n",
       "                                                                                                                     cleaned data  \n",
       "4320  we are trying to contact todays draw shows that you have won a ps800 prize call 09050001808 from land claim valid12hrs only  \n",
       "4321                                                                                   bloomberg center why apply for your future  \n",
       "4322                                    win a ps200 shopping spree every week starting 2 play text store to tscs08714740323 age16  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[4320:4322,['text','cleaned data']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2816810e",
   "metadata": {},
   "source": [
    "## Text Preprocessing Step 4\n",
    "#### Stripping Extra Spaces\n",
    "Stripping helps remove spaces at the beginning and the end of the string/sentence.\n",
    "The extra spaces in between the characters and the spaces at the start or end of the string do not add any value to the model, and will rather slow down its computation speed.\n",
    "Thus, we can remove these extra spaces to make the model more efficient and targeted during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b9c46ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    new_text = data['cleaned text'][i].strip()\n",
    "    text.append(new_text)\n",
    "data['cleaned data'] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d1b4661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before stripping the data :  \"       Sure thing big man. i have hockey elections at 6 shouldn€˜t go on longer than an hour though     \"\n",
      "After stripping the data :  Sure thing big i have hockey elections at 6 go on longer than an hour though\n"
     ]
    }
   ],
   "source": [
    "print(\"Before stripping the data : \",data['text'][6])\n",
    "print(\"After stripping the data : \",data['cleaned data'][6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19fbaa",
   "metadata": {},
   "source": [
    "## Text Preprocessing Step 5\n",
    "### Spellchecking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2d30bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Spellchecker and setting the language to english\n",
    "\n",
    "spell = Speller(lang = 'en')\n",
    "\n",
    "#defining a function which will take input as text break\n",
    "def autospell(text):\n",
    "    \n",
    "    word = text.split()\n",
    "    spells = [spell(w) for w in word]\n",
    "    return\" \".join(spells)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48561cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    \n",
    "    new_text = autospell(data['cleaned data'][i])\n",
    "    text.append(new_text)\n",
    "    \n",
    "data['cleaned_data']= text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf97ec66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hope you are having a good week. Just checking in ñó ñó</td>\n",
       "      <td>Hope you are having a good Just checking in no no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K..going bacckk to stävänger</td>\n",
       "      <td>back to stranger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Am also dong in cbe ony. Bt have to pay</td>\n",
       "      <td>Am also dong in cbe Bt have to pay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "0  Hope you are having a good week. Just checking in ñó ñó   \n",
       "1                             K..going bacckk to stävänger   \n",
       "2                  Am also dong in cbe ony. Bt have to pay   \n",
       "\n",
       "                                        cleaned_data  \n",
       "0  Hope you are having a good Just checking in no no  \n",
       "1                                   back to stranger  \n",
       "2                 Am also dong in cbe Bt have to pay  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[0:2,['text','cleaned_data']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed36e6b",
   "metadata": {},
   "source": [
    "## Text Preprocessing Step 6\n",
    "### Stop word Removal\n",
    "The simple idea with stop word removal is to exclude words that appear frequently throughout all the documents in the corpus. Pronouns and articles are typically categorized as stop words.\n",
    "\n",
    "- To implement this, we have two Python libraries that are built to be used for NLP operations. Let's have a look at them and we'll implement them through both libraries.\n",
    "\n",
    "- Before removing the stop words from the text however, let's have a look at the key words from the original data through visual representation.\n",
    "\n",
    "### Word Cloud\n",
    "- A word cloud (also known as a tag cloud or text cloud) is a visual representation of text, in which the words appear bigger the more often they are mentioned. Word clouds are great for visualizing unstructured text data and getting insights on trends and patterns.\n",
    "\n",
    "Let's look at the top 100 unique words in original messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "844477e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 365343 words in the combination of all texts.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [41]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m words in the combination of all texts.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(all_texts)))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# lower max_font_size, change the maximum number of word and lighten the background:\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m wordcloud \u001b[38;5;241m=\u001b[39m \u001b[43mWordCloud\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_font_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwhite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m12\u001b[39m))\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(wordcloud)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:639\u001b[0m, in \u001b[0;36mWordCloud.generate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m    The input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;124;03m    self\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:621\u001b[0m, in \u001b[0;36mWordCloud.generate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;124;03m\"\"\"Generate wordcloud from text.\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \n\u001b[0;32m    606\u001b[0m \u001b[38;5;124;03mThe input \"text\" is expected to be a natural text. If you pass a sorted\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;124;03mself\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    620\u001b[0m words \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_text(text)\n\u001b[1;32m--> 621\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_from_frequencies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\wordcloud\\wordcloud.py:508\u001b[0m, in \u001b[0;36mWordCloud.generate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    505\u001b[0m transposed_font \u001b[38;5;241m=\u001b[39m ImageFont\u001b[38;5;241m.\u001b[39mTransposedFont(\n\u001b[0;32m    506\u001b[0m     font, orientation\u001b[38;5;241m=\u001b[39morientation)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# get size of resulting text\u001b[39;00m\n\u001b[1;32m--> 508\u001b[0m box_size \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtextbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfont\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransposed_font\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# find possible places using integral image:\u001b[39;00m\n\u001b[0;32m    510\u001b[0m result \u001b[38;5;241m=\u001b[39m occupancy\u001b[38;5;241m.\u001b[39msample_position(box_size[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    511\u001b[0m                                    box_size[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmargin,\n\u001b[0;32m    512\u001b[0m                                    random_state)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageDraw.py:671\u001b[0m, in \u001b[0;36mImageDraw.textbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    669\u001b[0m     font \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgetfont()\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(font, ImageFont\u001b[38;5;241m.\u001b[39mFreeTypeFont):\n\u001b[1;32m--> 671\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly supported for TrueType fonts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    672\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embedded_color \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfontmode\n\u001b[0;32m    673\u001b[0m bbox \u001b[38;5;241m=\u001b[39m font\u001b[38;5;241m.\u001b[39mgetbbox(\n\u001b[0;32m    674\u001b[0m     text, mode, direction, features, language, stroke_width, anchor\n\u001b[0;32m    675\u001b[0m )\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "all_texts = \" \".join(texts for texts in data.text)\n",
    "print (\"There are {} words in the combination of all texts.\".format(len(all_texts)))\n",
    "\n",
    "# lower max_font_size, change the maximum number of word and lighten the background:\n",
    "wordcloud = WordCloud(max_font_size = 40, max_words=100, background_color=\"white\").generate(all_texts)\n",
    "plt.figure(figsize=(8,12))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf20de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cf0e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141e0b94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02601bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8d1104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1828704f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad2a992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
